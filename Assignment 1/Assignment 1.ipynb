{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIa-poEHfw5Z"
   },
   "source": [
    "# Assignment 1 (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGU057DfgTIL"
   },
   "source": [
    "* In this project you are given a dataset of housing housing price prediction. \n",
    "Dataset description is found in the given datasets.\n",
    "\n",
    "* The goal of the project is to predict the price of a house given its attributes. \n",
    "Therefore, the problem is a regression task. \n",
    "\n",
    "* You need to build a random forest that consists of multiple decision trees (for regression) from the given training data set. Then, apply it on the test set and submit your code to generate predictions.\n",
    "You need to build the random forest and decision trees from scratch. (I.e., it is not allowed to use existing machine learning libraries or packages such as sklearn.)\n",
    "\n",
    "* You may use any programming language/environment of your choice, but you are required to submit the complete source code to produce the output\n",
    "If you use anything other than jupyter notebook, submit an executable and run that from the main function of the jupyter notebook so that the prediction generation is automated. We can provide assistance with this.\n",
    "The output (a single file with the predictions for each test instance) must be generated automatically using the approach implemented by you. Submitting predictions/code from any other source (Internet, another student, etc.) is considered cheating and will result in immediate disqualification (i.e., dismissal from the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kut1m20f4zR"
   },
   "source": [
    "## Part 1: Preprocessing and dataset analysis (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yANfSgagRJq"
   },
   "source": [
    "* The given dataset is quite complex, it has many attributes, and not all of them are useful! \n",
    "Training on such dataset results in a bad accuracy. And this is exactly the point! \n",
    "\n",
    "* \"Understanding the question is half the answer\". In data mining, understanding the dataset is half the answer! \n",
    "\n",
    "* In part 1 you need to analyze the dataset and make it clean. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4xjsBzYlfjq"
   },
   "source": [
    "### Load the dataset and explore (5 points)\n",
    "\n",
    "* Load the dataset, view the dataset and the shape of it, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AUvifadOf4G-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1560, 80)\n",
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "train_data_file = 'housing_price_train.csv'\n",
    "test_data_file = 'housing_price_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_file)\n",
    "test_data = pd.read_csv(test_data_file)\n",
    "cols = train_data.columns\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(cols)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWmPCu5hmAIj"
   },
   "source": [
    "### Clean the dataset (10 points)\n",
    "\n",
    "* We cannot train on a 'dirty' dataset! There are duplicated, Null, and missing values that you need to take care of!\n",
    "\n",
    "* Drop all columns which have null values >= 70 % and drop all rows which have null values >= 70 %.\n",
    "\n",
    "* You need to take care of categorial data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "exQbzeH7mM-I"
   },
   "outputs": [],
   "source": [
    "def PreprocessingData(db, threshold = 70):\n",
    "    \"\"\"\n",
    "        TODO\n",
    "        Show NULL values for each columns in dataset and thier percentage\n",
    "        Drop all columns which have null values >= 70 % \n",
    "        Drop all rows which have null values >= 70 %\n",
    "        Fill all missing values with the (mean, mode)\n",
    "\n",
    "    \"\"\"\n",
    "    # 1. Show null values and their percentage\n",
    "    columns_with_null_values = (db.isna().sum().loc[lambda x: x > 0]).to_frame()\n",
    "    columns_with_null_values[\"Percentage\"] = columns_with_null_values.apply(lambda x: (x / len(db)) * 100)\n",
    "    print(\"\\nColumns with null values: \")\n",
    "    print(columns_with_null_values)\n",
    "    \n",
    "    \n",
    "    # 2. Drop columns with more than 70% null values\n",
    "    columns_to_remove = (columns_with_null_values[\"Percentage\"].loc[lambda x: x > threshold]).index\n",
    "    print(\"\\nColumns to Remove: \")\n",
    "    print(columns_to_remove)\n",
    "    db.drop(columns_to_remove, axis = 'columns', inplace = True)\n",
    "    \n",
    "    # 3. Drop all rows with more than 70% null values\n",
    "    min_non_null_values = len(db.columns) - int((threshold * len(db.columns)) / 100)\n",
    "    print(\"\\nThreshold for at least 70% null values in a row: \")\n",
    "    print(min_non_null_values)\n",
    "    # No rows have more than 70% null values\n",
    "    if len(db.isna().sum(axis = 1).loc[lambda x: x > min_non_null_values]) == 0:\n",
    "        print(\"\\nNo rows have more than 70% Null Values.\")\n",
    "        print(db.isna().sum(axis = 1).loc[lambda x: x > min_non_null_values])\n",
    "    else:\n",
    "        db.dropna(axis = 'index', thresh = min_non_null_values, inplace = True)\n",
    "        print(\"\\nShape after dropping rows with at least 70% null values: \")\n",
    "        print(db.shape)\n",
    "    \n",
    "    # 4. Fill missing values (mean for numerical values and mode for categorical)\n",
    "    numeric_columns = list(db.select_dtypes(['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns)\n",
    "    categorical_columns = list(db.select_dtypes(include = ['object', 'category']).columns)\n",
    "    \n",
    "    for col in db.columns:\n",
    "        if col in ['Id']:\n",
    "            continue\n",
    "        elif col in numeric_columns:\n",
    "            db[col].fillna(db[col].mean(), inplace=True)\n",
    "        elif col in categorical_columns:\n",
    "            db[col].fillna(db[col].mode()[0], inplace=True)\n",
    "            \n",
    "    print(\"\\nNull Values after cleaning up the dataset: \")\n",
    "    print(db.isna().sum(axis=1).loc[lambda x: x > 0])\n",
    "    print(db.isna().sum(axis=0).loc[lambda x: x > 0])\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with null values: \n",
      "                 0  Percentage\n",
      "LotFrontage    259   17.739726\n",
      "Alley         1369   93.767123\n",
      "MasVnrType       8    0.547945\n",
      "MasVnrArea       8    0.547945\n",
      "BsmtQual        37    2.534247\n",
      "BsmtCond        37    2.534247\n",
      "BsmtExposure    38    2.602740\n",
      "BsmtFinType1    37    2.534247\n",
      "BsmtFinType2    38    2.602740\n",
      "Electrical       1    0.068493\n",
      "FireplaceQu    690   47.260274\n",
      "GarageType      81    5.547945\n",
      "GarageYrBlt     81    5.547945\n",
      "GarageFinish    81    5.547945\n",
      "GarageQual      81    5.547945\n",
      "GarageCond      81    5.547945\n",
      "PoolQC        1453   99.520548\n",
      "Fence         1179   80.753425\n",
      "MiscFeature   1406   96.301370\n",
      "\n",
      "Columns to Remove: \n",
      "Index(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], dtype='object')\n",
      "\n",
      "Threshold for at least 70% null values in a row: \n",
      "24\n",
      "\n",
      "No rows have more than 70% Null Values.\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Null Values after cleaning up the dataset: \n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Columns with null values: \n",
      "                 0  Percentage\n",
      "MSZoning         4    0.256410\n",
      "LotFrontage    237   15.192308\n",
      "Alley         1443   92.500000\n",
      "Utilities        2    0.128205\n",
      "Exterior1st      1    0.064103\n",
      "Exterior2nd      1    0.064103\n",
      "MasVnrType      16    1.025641\n",
      "MasVnrArea      15    0.961538\n",
      "BsmtQual        45    2.884615\n",
      "BsmtCond        46    2.948718\n",
      "BsmtExposure    45    2.884615\n",
      "BsmtFinType1    43    2.756410\n",
      "BsmtFinSF1       1    0.064103\n",
      "BsmtFinType2    43    2.756410\n",
      "BsmtFinSF2       1    0.064103\n",
      "BsmtUnfSF        1    0.064103\n",
      "TotalBsmtSF      1    0.064103\n",
      "BsmtFullBath     2    0.128205\n",
      "BsmtHalfBath     2    0.128205\n",
      "KitchenQual      1    0.064103\n",
      "Functional       2    0.128205\n",
      "FireplaceQu    780   50.000000\n",
      "GarageType      80    5.128205\n",
      "GarageYrBlt     82    5.256410\n",
      "GarageFinish    82    5.256410\n",
      "GarageCars       1    0.064103\n",
      "GarageArea       1    0.064103\n",
      "GarageQual      82    5.256410\n",
      "GarageCond      82    5.256410\n",
      "PoolQC        1557   99.807692\n",
      "Fence         1247   79.935897\n",
      "MiscFeature   1505   96.474359\n",
      "SaleType         1    0.064103\n",
      "\n",
      "Columns to Remove: \n",
      "Index(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], dtype='object')\n",
      "\n",
      "Threshold for at least 70% null values in a row: \n",
      "23\n",
      "\n",
      "No rows have more than 70% Null Values.\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Null Values after cleaning up the dataset: \n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "train_data = PreprocessingData(train_data)\n",
    "test_data = PreprocessingData(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ8kz_a-mdNx"
   },
   "source": [
    "### Correlations! (5 points)\n",
    "\n",
    "* Now we have a clean dataset, but not all attributes are useful! \n",
    "\n",
    "* Display the corrlation between all features and the sales price. This will show you which feature affects sales price more. You may use *corr()* function. \n",
    "\n",
    "* Choose the most correlated features, and remove others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Irh60fo-nVtw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0   1          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1   2          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2   3          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3   4          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4   5          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig  ... EnclosedPorch 3SsnPorch ScreenPorch PoolArea  \\\n",
       "0    AllPub    Inside  ...             0         0           0        0   \n",
       "1    AllPub       FR2  ...             0         0           0        0   \n",
       "2    AllPub    Inside  ...             0         0           0        0   \n",
       "3    AllPub    Corner  ...           272         0           0        0   \n",
       "4    AllPub       FR2  ...             0         0           0        0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       0      2    2008        WD         Normal     208500  \n",
       "1       0      5    2007        WD         Normal     181500  \n",
       "2       0      9    2008        WD         Normal     223500  \n",
       "3       0      2    2006        WD        Abnorml     140000  \n",
       "4       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForest Algorithm can work well with the numerical columns but for categorical columns we need to convert them to numerical columns somehow. One common method to do so is to make each category into a column and items / rows with that category will have 1 in the respective column and 0 in others.\n",
    "\n",
    "We can use get_dummies method from pandas to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For correlation we will use 20% as the threshold.\n",
    "threshold = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "      <th>GarageFinish_Fin</th>\n",
       "      <th>GarageFinish_Unf</th>\n",
       "      <th>PavedDrive_N</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  LotArea  OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  \\\n",
       "0         65.0     8450            7       2003          2003       196.0   \n",
       "1         80.0     9600            6       1976          1976         0.0   \n",
       "2         68.0    11250            7       2001          2002       162.0   \n",
       "3         60.0     9550            7       1915          1970         0.0   \n",
       "4         84.0    14260            8       2000          2000       350.0   \n",
       "\n",
       "   BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...  GarageType_Attchd  \\\n",
       "0         706        150          856       856  ...                  1   \n",
       "1         978        284         1262      1262  ...                  1   \n",
       "2         486        434          920       920  ...                  1   \n",
       "3         216        540          756       961  ...                  0   \n",
       "4         655        490         1145      1145  ...                  1   \n",
       "\n",
       "   GarageType_BuiltIn  GarageType_Detchd  GarageFinish_Fin  GarageFinish_Unf  \\\n",
       "0                   0                  0                 0                 0   \n",
       "1                   0                  0                 0                 0   \n",
       "2                   0                  0                 0                 0   \n",
       "3                   0                  1                 0                 1   \n",
       "4                   0                  0                 0                 0   \n",
       "\n",
       "   PavedDrive_N  PavedDrive_Y  SaleType_New  SaleType_WD  \\\n",
       "0             0             1             0            1   \n",
       "1             0             1             0            1   \n",
       "2             0             1             0            1   \n",
       "3             0             1             0            1   \n",
       "4             0             1             0            1   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting SalePrice column since we only want the correlation between Columns and SalePrice\n",
    "# And taking absolute value cause there could be a negative correlation between Attribute and SalePrice\n",
    "train_data_correlation = train_data.corr()['SalePrice'].abs()\n",
    "columns_to_drop = train_data_correlation.loc[lambda x: x < threshold].index.to_list()\n",
    "train_data_cleaned = train_data.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "train_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 68) (1560, 67)\n"
     ]
    }
   ],
   "source": [
    "# Next we remove the same columns from test_data that we just dropped from train_data with low enough correlation\n",
    "training_cols = train_data_cleaned.columns.tolist()\n",
    "test_cols = test_data.columns.tolist()\n",
    "\n",
    "dropped_training_cols = np.setdiff1d(test_cols, training_cols)\n",
    "test_data_cleaned = test_data.drop(dropped_training_cols, axis = 1, inplace = False)\n",
    "print(train_data_cleaned.shape, test_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'MSZoning_RL', 'MSZoning_RM', 'LotShape_IR1', 'LotShape_Reg', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_StoneBr', 'HouseStyle_2Story', 'RoofStyle_Gable', 'RoofStyle_Hip', 'Exterior1st_VinylSd', 'Exterior2nd_VinylSd', 'MasVnrType_None', 'MasVnrType_Stone', 'ExterQual_Ex', 'ExterQual_Gd', 'ExterQual_TA', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'BsmtQual_Ex', 'BsmtQual_Gd', 'BsmtQual_TA', 'BsmtExposure_Gd', 'BsmtExposure_No', 'BsmtFinType1_GLQ', 'HeatingQC_Ex', 'HeatingQC_TA', 'CentralAir_N', 'CentralAir_Y', 'Electrical_SBrkr', 'KitchenQual_Ex', 'KitchenQual_Gd', 'KitchenQual_TA', 'FireplaceQu_Ex', 'GarageType_Attchd', 'GarageType_BuiltIn', 'GarageType_Detchd', 'GarageFinish_Fin', 'GarageFinish_Unf', 'PavedDrive_N', 'PavedDrive_Y', 'SaleType_New', 'SaleType_WD', 'SaleCondition_Partial']\n",
      "SalePrice\n"
     ]
    }
   ],
   "source": [
    "# To make indexing easier for us later we rearrange the columns in train_data for SalePrice to be the last column\n",
    "list_of_columns = list(train_data_cleaned.columns)\n",
    "list_of_columns.remove('SalePrice')\n",
    "list_of_columns.append('SalePrice')\n",
    "train_data_cleaned = train_data_cleaned.reindex(columns = list_of_columns)\n",
    "print(train_data_cleaned.iloc[:,:-1].columns.to_list())\n",
    "print(train_data_cleaned.iloc[:,-1].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhnNAO-wnXM6"
   },
   "source": [
    "## Part 2: Decision Tree (45 points)\n",
    "#### Building a Decision Tree:\n",
    "A Decision tree consists of nodes connected by edges. A decision tree is typically, a binary tree, which has the following properties:\n",
    "- One node is marked as Root node\n",
    "- Every node other than the root has a parent node\n",
    "- Each node can have at most 2 child nodes (left edge & right edge)\n",
    "- Leaf node is the node which contains pure data or when we reach to the maximum depth \n",
    "\n",
    "To create the decision tree model for scratch you need to create two classes (a class for the node, for example \"class DecisionNode():\" and a class for Decision Tree model, for example \"class RegressionDecisionTree():\")\n",
    "\n",
    "\n",
    "1- DecisionNode class used to save some values for each node we do the spliting on it until we reach the leaf node\n",
    "so we will save the following values for the node:\n",
    "- feature: feature index.\n",
    "- threshold: the value we used to split the data on.\n",
    "- value: the average value for the leaf node.\n",
    "- True_Branch: if the condition is true.\n",
    "- False_Branch: if the condition is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cYNFB7QY-SJK"
   },
   "outputs": [],
   "source": [
    "class DecisionNode():\n",
    "    def __init__(self, feature_idx=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature_idx = feature_idx # index of the feature that is used\n",
    "        self.threshold = threshold     # threshold value for feature when making the decision\n",
    "        self.value = value # Average value if the node is a leaf in the tree\n",
    "        self.true_branch = true_branch # the node we go to if decision returns True\n",
    "        self.false_branch = false_branch # the node we go to if decision returns False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYpCv95F-SJK"
   },
   "source": [
    "# Decision Tree Class\n",
    "This Class consists the following functions:\n",
    "<ol>\n",
    "<li> <b>build_tree</b>: used to create the decision tree nodes</li> \n",
    "<li> <b>calc_variance_reduction</b> : measure the impurity by using variance reduction measure (like MSE) </li> \n",
    "the function takes three parameters (parentRec: the records for the target before split,and the left and right records after splitting. This function used to measure the impurity for each node and decide if we will split or not.\n",
    "<li> <b>majority_vote</b>: used to calculate values for the leaf nodes records which equal to the mean of these records.</li> \n",
    "<li><b>split_by_feature</b>: this function take the feature and the threshold and check if the feature is numerical so it split the records into two node (true which is the left edge and false which is the right edge)\n",
    "if the feature is categorical so it split where the values equal to the threshold</li>\n",
    "<li> <b>fit</b>: Used to train the dataset after spliting the data into two part x: features, y: target</li>\n",
    "<li><b>predict_value</b>: used to predict the value for each record, it is a recursive method to find the leaf node that corresponds to prediction\n",
    "<li><b>predict</b>: take all records for the test data and iterate into each record to predit the y(target) value and save the result into a prediction list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HSe6v4r1-SJK"
   },
   "outputs": [],
   "source": [
    "class RegressionDecisionTree():\n",
    "    # constructor\n",
    "    def __init__(self, min_VarianceReduction=1e-7, max_depth=5):        \n",
    "        self.root = None # root of this tree\n",
    "        self.min_VarianceReduction = min_VarianceReduction # minimum VarianceReduction to allow splitting\n",
    "        # used to stopping conductions\n",
    "        self.max_depth = max_depth # maximum depth the tree grows to\n",
    " \n",
    "\n",
    "    # used to create the decision tree nodes\n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        # we will use decision dictionary to save the feature and the threshold we build the tree on \n",
    "        decision = None\n",
    "        # we will use subtrees dictionary to save the feature and the threshold we build the tree on \n",
    "        subtrees = None\n",
    "        largest_variance_Reduction = 0\n",
    "        # add y as last column of X\n",
    "        df = pd.concat((X, y), axis=1)\n",
    "        n_rows, n_features = X.shape\n",
    "        if current_depth <= self.max_depth:\n",
    "            # iterate through every feature\n",
    "            for feature_idx in range(n_features):\n",
    "                # values of that column\n",
    "                feature_values = X.iloc[:, feature_idx]                \n",
    "                unique_values = feature_values.unique()                \n",
    "                for threshold in unique_values:\n",
    "                    X_trueEdge, X_falseEdge = self.split_by_feature(df, feature_idx, threshold)\n",
    "                    if len(X_trueEdge) > 0 and len(X_falseEdge) > 0:\n",
    "                        y_true = X_trueEdge.iloc[:,-1]\n",
    "                        y_false = X_falseEdge.iloc[:,-1]                        \n",
    "                        # Calculate impurity\n",
    "                        VarianceRed = self.Calc_variance_reduction(y, y_true, y_false)\n",
    "                        # Keep track of which feature gave the largest information gain\n",
    "                        if VarianceRed > largest_variance_Reduction:\n",
    "                            largest_variance_Reduction = VarianceRed\n",
    "                            decision = {\"feature_idx\":feature_idx, \"threshold\":threshold}\n",
    "                            subtrees = {\"X_true\":X_trueEdge.iloc[:,:-1],\n",
    "                                        \"y_true\":y_true,\n",
    "                                        \"X_false\":X_falseEdge.iloc[:,:-1],\n",
    "                                        \"y_false\":y_false}\n",
    "\n",
    "        # we will construct new branch of tree if the variance_Reduction is larger than minimum variance_Reduction that we've defined\n",
    "        if largest_variance_Reduction > self.min_VarianceReduction:\n",
    "            true_branch = self.build_tree(subtrees[\"X_true\"], subtrees[\"y_true\"], current_depth+1)\n",
    "            false_branch = self.build_tree(subtrees[\"X_false\"], subtrees[\"y_false\"], current_depth+1)\n",
    "            return DecisionNode(feature_idx=decision[\"feature_idx\"], threshold=decision[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "        # at leaf node we calculate the mean for the records\n",
    "        leaf_value = self.majority_vote(y)\n",
    "        return DecisionNode(value=leaf_value)\n",
    "                        \n",
    "    # measure the impurity by using variance reduction measure (like MSE)\n",
    "    # left_edgeRec= True edge: where condition is true\n",
    "    # Right_edgeRec= False edge: where condition is false\n",
    "    def Calc_variance_reduction(self, parentRec, left_edgeRec, Right_edgeRec):   \n",
    "        n = len(parentRec)\n",
    "        left_weight = len(left_edgeRec) / n\n",
    "        right_weight = len(Right_edgeRec) / n\n",
    "        \n",
    "        parent_variance = parentRec.var()\n",
    "        left_variance = left_edgeRec.var()\n",
    "        right_variance = Right_edgeRec.var()\n",
    "        \n",
    "        # return the VarReduction = variance for parent - (Weight * var(leftEdge) + Weight * var(RightEdge)    \n",
    "        return (parent_variance - ((left_weight * left_variance) + (right_weight * right_variance)))\n",
    "    \n",
    "    def majority_vote(self, y):\n",
    "        # Just taken from the Helping material\n",
    "        return y.value_counts().idxmax()\n",
    "    \n",
    "    def split_by_feature(self, X, feature_idx, threshold):\n",
    "        # split the data into left_edge & right_edge depends one specified feature and the threshold\n",
    "        condition_satisfied_indexes = (X.iloc[:, feature_idx] >= threshold) == True\n",
    "        condition_not_satisfied_indexes = (X.iloc[:,feature_idx] >= threshold) == False\n",
    "        \n",
    "        left_tree = X[condition_satisfied_indexes]\n",
    "        right_tree = X[condition_not_satisfied_indexes]\n",
    "        # return left & right edges\n",
    "        return(left_tree, right_tree)\n",
    "\n",
    "    \n",
    "    # Used to train the dataset after spliting the data into x: features, y: target\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict_value(self, xTest, tree = None):\n",
    "        # Just taken from the Helping material\n",
    "        # recursive method to find the leaf node that corresponds to prediction\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        feature_value = xTest[tree.feature_idx]\n",
    "        branch = tree.false_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.true_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "\n",
    "        return self.predict_value(xTest, branch)\n",
    "\n",
    "    # to predict the value we need to pass the all records for features and we save the prediction for each records into a list\n",
    "    def predict(self, XTest):\n",
    "        y_pred = []\n",
    "        for idx, row in XTest.iterrows():           \n",
    "            y_pred.append(self.predict_value(row.values))\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9aqjovq-SJM"
   },
   "source": [
    "- To Check the Accuracy for our prediction we use CalcAccuracy function which take the actual values for the test dataset and the predicted values and apply the RMSE formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "24p2WfE8-SJN"
   },
   "outputs": [],
   "source": [
    "def CalcAccuracy(Actual_Y, Predicted_y):\n",
    "    return math.sqrt(np.square(np.subtract(Actual_Y, Predicted_y)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_2Ve9v--SJN"
   },
   "source": [
    "- Build decision tree model\n",
    "- Fit the model\n",
    "- Predict the values from test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7dJKxolT-SJN"
   },
   "outputs": [],
   "source": [
    "decission_tree = RegressionDecisionTree()\n",
    "decission_tree.fit(train_data_cleaned.iloc[:,:-1], train_data_cleaned.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only until 1459 because test_data has some additional rows than the labels given in submissions.csv\n",
    "predicted_y = (decission_tree.predict(test_data_cleaned))[:1459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_file = 'sample_submission.csv'\n",
    "test_labels = pd.read_csv(test_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46898.04901338459"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcAccuracy(list(test_labels[\"SalePrice\"]), predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So our model is off by around 47000 NOK value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvzaxcPAoJsk"
   },
   "source": [
    "## Part 3: Random Forest (20 points)\n",
    "#### Random forest class\n",
    "- the Class consist of the following functions:\n",
    "<ul>\n",
    "    <li>Constructor: consists of the subset data (Training & Testing) dataset after preprocessing and a list of deciceion tree objects </li>    \n",
    "    <li>Subsampling: Bagging we will take random sample with replacement for the Training dataset </li>\n",
    "    <li>build_model: first make subsample for the training dataset, then split the data into featurespart(X) and targetpart(Y), then take 10 samples of the feature part, finally build the decision tree (fit), this function take the number of DT that we want to build</li>\n",
    "    <li>predict: take the test dataset and make the prediction for the target field in all the tree in the random forest then take the mean for the prediction in each tree, finally add the mean of prediction to a list of predition </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a00zi12Q-SJO"
   },
   "outputs": [],
   "source": [
    "class RF(object):\n",
    "    def __init__(self):\n",
    "        self.Traindata = None  # training data set (loaded into memory)\n",
    "        self.Testdata = None  # Test data set for prediction        \n",
    "        self.trees = []  # list of decision trees \n",
    "          \n",
    "\n",
    "     # This function generate a subsample with replacement\n",
    "    def __subsampling(self, train_set, sample_size_ratio):       \n",
    "        sample_number = round(len(train_set) * sample_size_ratio)\n",
    "        return train_set.sample(sample_number, replace = True)\n",
    "        \n",
    "    def build_model(self, train_set, sample_size_ratio, number_of_trees):\n",
    "        for i in range(number_of_trees):\n",
    "            TrainingSample = self.__subsampling(train_set, sample_size_ratio)\n",
    "            tree = RegressionDecisionTree()\n",
    "            tree.fit(TrainingSample.iloc[:,:-1], TrainingSample.iloc[:,-1])\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def predict(self, test_set):\n",
    "        n = len(test_set)\n",
    "        m = len(self.trees)\n",
    "        forest_pred = np.zeros((n, m))\n",
    "        counter = 0\n",
    "        result = []\n",
    "        for tree in self.trees:\n",
    "            forest_pred[:, counter] = tree.predict(test_set)\n",
    "            counter += 1\n",
    "\n",
    "        result = np.mean(forest_pred, axis = 1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITGUmaXc-SJO"
   },
   "source": [
    "### Create Random Forest\n",
    "\n",
    "* Create 10 Decision Tree in the randomforest\n",
    "* Train the random forest with the dataset\n",
    "* Use the created random forest to predict the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SjqaGyyl-qoY"
   },
   "outputs": [],
   "source": [
    "forest = RF()\n",
    "# This takes a long time to run\n",
    "# I am using a very small sample_size_ratio so that the random forest trains faster\n",
    "forest.build_model(train_data_cleaned, 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predicted_y = (forest.predict(test_data_cleaned))[:1459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38912.07132675759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcAccuracy(list(test_labels[\"SalePrice\"]), forest_predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVGAlCDkoRfo"
   },
   "source": [
    "## Part4: Comparison! (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tHF7qjiBl6A"
   },
   "source": [
    "Now that you have finished implementing your Random Forest, it's time for some experiments and analysis! \n",
    "\n",
    "* Use the Random Forest in the scikit-learn library and train it on the same dataset. \n",
    "\n",
    "* Compare the accuracy given by your Random Forest to the scikit-learn one. \n",
    "\n",
    "* Increase the number of trees in your Random Forest. Does it improve the accuracy? \n",
    "\n",
    "* Make a table for comparing your Random Forest accuracy with different number of trees with the scikit-learn one. What is your conclusion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sklearn_forest = RandomForestClassifier(n_estimators = 100)  \n",
    "sklearn_forest.fit(train_data_cleaned.iloc[:,:-1], train_data_cleaned.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_forest_predicted_y = sklearn_forest.predict(test_data_cleaned)[:1459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45688.66962014401"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcAccuracy(list(test_labels[\"SalePrice\"]), sklearn_forest_predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training with 1 number of trees in random forest!\n",
      "Done Training with 2 number of trees in random forest!\n",
      "Done Training with 3 number of trees in random forest!\n",
      "Done Training with 4 number of trees in random forest!\n",
      "Done Training with 5 number of trees in random forest!\n",
      "Done Training with 6 number of trees in random forest!\n",
      "Done Training with 7 number of trees in random forest!\n",
      "Done Training with 8 number of trees in random forest!\n",
      "Done Training with 9 number of trees in random forest!\n",
      "Done Training with 10 number of trees in random forest!\n"
     ]
    }
   ],
   "source": [
    "number_of_trees_list = [x for x in range(1, 11)]\n",
    "result_table = pd.DataFrame(index = number_of_trees_list, columns = [\"Our Random Forest\", \"SKLearn Random Forest\"])\n",
    "\n",
    "for i in number_of_trees_list:\n",
    "    forest = RF()\n",
    "    # This takes a long time to run\n",
    "    forest.build_model(train_data_cleaned, 0.1, i)\n",
    "    forest_predicted_y = (forest.predict(test_data_cleaned))[:1459]\n",
    "    our_forest_accuracy = CalcAccuracy(list(test_labels[\"SalePrice\"]), forest_predicted_y)\n",
    "    \n",
    "    # Multiplying by 10 because otherwise the sklearn random forest classifier performs very bad\n",
    "    sklearn_forest = RandomForestClassifier(n_estimators = (i * 10))  \n",
    "    sklearn_forest.fit(train_data_cleaned.iloc[:,:-1], train_data_cleaned.iloc[:,-1])\n",
    "    sklearn_forest_predicted_y = sklearn_forest.predict(test_data_cleaned)[:1459]\n",
    "    sklearn_forest_accuracy = CalcAccuracy(list(test_labels[\"SalePrice\"]), sklearn_forest_predicted_y)\n",
    "    \n",
    "    print(\"Done Training with \" + str(i) + \" number of trees in random forest!\")\n",
    "    # Add to dataframe here\n",
    "    result_table.loc[i, ['Our Random Forest','SKLearn Random Forest']] = [our_forest_accuracy, sklearn_forest_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Our Random Forest SKLearn Random Forest\n",
      "1            46897.5               62694.3\n",
      "2            48082.6               51305.8\n",
      "3            44863.5               50356.3\n",
      "4            43318.7               50138.4\n",
      "5            48345.6               49119.8\n",
      "6            41834.4               47469.5\n",
      "7            41010.1               48471.7\n",
      "8            39019.6               49020.3\n",
      "9            41345.6               47740.9\n",
      "10           40162.7               47034.1\n"
     ]
    }
   ],
   "source": [
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e42f74ecac23521ece3572bae462a7c7939cd558a6fbb59afafe09d03193ca58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
